{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../python')\n",
    "from get_vs import locate_vs\n",
    "from misc import *\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "import gcsfs\n",
    "from dask_kubernetes import KubeCluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_pangeo_data = True # True if in Pangeo binder, False if in laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coordinates of the virtual stations in [Hydroweb](http://hydroweb.theia-land.fr) don't match with the rivers in [HydroSHEDS](http://www.hydrosheds.org). In order to find the corresponding coordinates in HydroSHEDS, we look around the original position for the pixel with the biggest accumulated flow which is bigger than a minimum flow. If no such flow is found, we look further around, until we find one (but not too far away, in which case we just drop the virtual station). The new_lat/new_lon are the coordinates of this pixel, if found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../data/amazonas/amazonas.pkl'):\n",
    "    df = locate_vs('../data/amazonas/amazonas.txt', pix_nb=20, acc_min=1_000_000)\n",
    "    df.to_pickle('../data/amazonas/amazonas.pkl')\n",
    "else:\n",
    "    df = pd.read_pickle('../data/amazonas/amazonas.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_latlon = df[['new_lat', 'new_lon']].dropna().values\n",
    "print(f'Out of {len(df)} virtual stations in Hydroweb, {len(sub_latlon)} could be found in HydroSHEDS.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following coordinates are duplicated because some virtual stations fall inside the same pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_latlon = [(-4.928333333333334, -62.733333333333334), (-3.8666666666666667, -61.6775)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ll = df[['new_lat', 'new_lon']].dropna()\n",
    "duplicated = df_ll[df_ll.duplicated(keep=False)]\n",
    "duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(duplicated) / 2 == len(rm_latlon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the subbasins in the hydrologic partition (including virtual stations)\n",
    "if is_pangeo_data:\n",
    "    fs = gcsfs.GCSFileSystem(project='pangeo-data')\n",
    "    labels = [os.path.basename(path[:-1]) for path in fs.ls('pangeo-data/ws_mask/amazonas')]\n",
    "else:\n",
    "    labels = os.listdir('ws_mask/amazonas')\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_without_vs = list(labels)\n",
    "labels_with_vs = []\n",
    "for l in tqdm(labels):\n",
    "    if is_pangeo_data:\n",
    "        ds = xr.open_zarr(gcsfs.GCSMap(f'pangeo-data/ws_mask/amazonas/{l}'))\n",
    "    else:\n",
    "        ds = xr.open_zarr(f'ws_mask/amazonas/{l}')\n",
    "    da = ds['mask']\n",
    "    olat, olon = da.attrs['outlet']\n",
    "    idx = df_ll[(olat-0.25/1200<df_ll.new_lat.values) & (df_ll.new_lat.values<olat+0.25/1200) & (olon-0.25/1200<df_ll.new_lon.values) & (df_ll.new_lon.values<olon+0.25/1200)].index.values\n",
    "    labels_with_vs.append(l)\n",
    "    if len(idx) > 0:\n",
    "        labels_without_vs.remove(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tree = get_label_tree(labels_with_vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_pangeo_data:\n",
    "    cluster = KubeCluster(n_workers=10)\n",
    "    client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipitation = get_precipitation('2014-03-11', '2014-03-12 01:00:00')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
